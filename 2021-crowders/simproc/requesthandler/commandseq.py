"""Requests that include command sequences"""

#Standard library
from __future__ import print_function, division #Python 2 compatibility
import sys

#Site packages
import pandas as pd

#This package
from . import nested
from . import yaml_manager
from . import pickle_manager
from . import customization
from . import logging

logger=logging.getLogger(__name__)

class WithCommandsRequest(customization.CustomizableRequest):
  """A customizeable request that supports command sequences"""

  def init_command_sequence(self,attrpath):
    """Initializations needed for a general command sequence

    Arguments:

      - attrpath = attribute path to the command list
    
    No return value."""
    #Set up empty command list if not already present
    if self.get_nested_default(attrpath,None) is None:
      self.set_nested(attrpath,[])
    commandseq=self.get_nested(attrpath)
    #Get input files
    self._more_inputfiles=getattr(self,'_more_inputfiles',[]) #Initialize attribute if it doesn't already exist
    self._more_inputfiles+=self.list_iofiles(commandseq,['infpath'],'_inputfiles','_infile_args')
    #Get output files
    self._more_outputfiles=getattr(self,'_more_outputfiles',[]) #Initialize attribute if it doesn't already exist
    self._more_outputfiles+=self.list_iofiles(commandseq,['outfpath'],'_outputfiles','_outfile_args')
    #Done
    return

  def process_command_sequence(self,attrpath,singlefunc=None,positional=False):
    """Process a list of commands

    Arguments:

      - attrpath = attribute path to the command list
      - singlefunc = the name (as string) of the method to be called for all items in the sequence.
        Set this to ``None`` if the command list must include the function name.
        Otherwise, the command list will consist only of the arguments.
      - positional = boolean, True to use positional arguments, False to use keyword arguments
        If False, the arguments are provided as a dictionary.
        If True, the arguments are provided as a sequence.

    No return value."""
    logger.debug("Processing command sequence.",request_class=type(self).__name__,request_name=getattr(self,"name",None),attrpath=attrpath)
    if singlefunc is not None:
      funcname = singlefunc
    for cmd in self.get_nested_default(attrpath,[]):
      try:
        #Function name and arguments
        if singlefunc is None:
          funcname, arguments = cmd
        else:
          arguments = cmd
        #Call it
        logger.debug("Processing command.",request_name=getattr(self,"name",None),funcname=funcname)
        if positional:
          getattr(self,funcname)(*arguments)
        else:
          getattr(self,funcname)(**arguments)
        logger.debug("Completed command.",request_name=getattr(self,"name",None),funcname=funcname)
      except Exception as einst:
        raise Exception("Exception occured in %s for command: %s"%(attrpath,str(cmd))) from einst
    logger.debug("Completed command sequence.",request_class=type(self).__name__,request_name=getattr(self,"name",None),attrpath=attrpath)
    return

  def list_iofiles(self,cmdlist,filearg_list,helper_tag,funcattr):
    """Get a list of all the input/output files generated by a command sequence.

    Arguments:

      - cmdlist = list of commands,
        each command consists of pair (cmdname, arguments):

          - cmdname = name of data extraction method of the simulator class
          - arguments = dictionary of all arguments needed by the extraction method

      - filearg_list = list of command arguments potentially containing files
      - helper_tag = suffix to add to the command names to get the helper function for that command
          A helper function will provide the input/output files when called.
      - funcattr = attribute of the function that, if present, will contain a list of the arguments with io files
    
    The detection of io files works as follows, for each command in the sequence:

      - If the function has the specified attribute, that is used to get files.
      - If the helper function exists, it is called to get the files.
      - If NEITHER of the above, the `filearg_list` is used.

    Return:

      - iofiles = list of input/output files, in the form passed in the command list"""
    #Initalize the output list
    iofiles=[]
    #Go through all commands in the list
    for cmdname, arguments in cmdlist:
      use_default=True #Until we find out otherwise
      #Look for the attribute
      cmd_func=getattr(self,cmdname)
      if hasattr(cmd_func,funcattr):
        specific_arglist=getattr(cmd_func,funcattr)
        present_args=[n for n in specific_arglist if n in arguments.keys()]
        iofiles += [arguments[n] for n in present_args]
        use_default=False
      #Look for the helper function
      helperfunc=cmdname+helper_tag
      if hasattr(self,helperfunc):
        iofiles += getattr(self,helperfunc)(**arguments)
        use_default=False
      #Use default argument list if necessary
      if use_default:
        #Check default list of possible arguments that could contain the name of an output file
        present_args=[n for n in filearg_list if n in arguments.keys()]
        iofiles += [arguments[n] for n in present_args]
    return iofiles

  def store_module_contents(self,outattr,modpath,getname):
    """Load a function/class/etc from a module and store it as an attribute.

    Note that if the target is a function, this is NOT the same as making the function a method.
    When it is called, it is NOT passed ``self`` as the first argument.

    Arguments:

      - outattr = nested path to attribute to store data
      - modpath = path to the module containing the function
      - getname = name of the target within the module"""
    #Get path to module
    modpath=self.render(modpath)
    #Load module
    the_mod=customization.load_module_from_path(modpath)
    #Get function from module
    the_target = getattr(the_mod,getname)
    #Store
    self.set_nested(outattr,the_target)

  def load_yaml(self,infpath,attrpath):
    """Read in data from a yaml file, and store it at the specified nested path

    Arguments:

      - infpath = path to input yaml file
      - attrpath = nested path to attribute to store data"""
    obj=yaml_manager.readfile(self.render(infpath))
    self.set_nested(attrpath,obj)

  def load_pickle(self,infpath,attrpath):
    """Read in data from a pickle file, and store it at the specified nested path

    Arguments:

      - infpath = path to input pickle file
      - attrpath = nested path to attribute to store data"""
    obj=pickle_manager.readfile(self.render(infpath))
    self.set_nested(attrpath,obj)

  def load_csv(self,infpath,attrpath,dtype_csv_fpath=None):
    """Load a CSV file into a dataframe

    Arguments:

      - infpath = path to the input CSV file
      - attrpath = attribute path to load the data into
      - dtype_csv = optional (but highly recommended), path to the CSV file containing data type definitions for the columns
    
    No return value."""
    fpt=self.renderstr(self.get_stored(infpath))
    if dtype_csv_fpath is None:
      df=pd.read_csv(fpt)
    else:
      dtype_fpath=self.renderstr(self.get_stored(dtype_csv_fpath))
      dtype_ser=pd.read_csv(dtype_fpath,index_col=0,squeeze=True,header=0)
      dtypes_dict=dtype_ser.to_dict()
      df=pd.read_csv(fpt,dtype=dtypes_dict)
    self.set_nested(attrpath,df)
    return

  def select_by_column(self,dfpath,outpath,col,val,tol=None):
    """Select a subset of a dataframe by the values of one column.

    Arguments:

      - dfpath = attribute path to dataframe
      - outpath = attribute path to store result
      - col = name of column, as string
      - val = value of column to select, as string
      - tol = optional tolerance for floating point comparison"""
    inframe=self.get_nested(dfpath)
    if tol is None:
      cond = (inframe[col]==val)
    else:
      cond = (inframe[col]<(val+tol)) & (inframe[col]>(val-tol))
    sel=inframe[cond]
    self.set_nested(outpath,sel)

  def save_yaml(self,attrpath,outfpath):
    """Save data from the specified nested path to a yaml file

    Arguments:

      - attrpath = nested path to attribute with data to store
      - outfpath = path to the output yaml file"""
    obj=self.get_nested(attrpath)
    yaml_manager.writefile(obj,self.render(outfpath))

  def save_pickle(self,attrpath,outfpath):
    """Save data from the specified nested path to a pickle file

    Arguments:

      - attrpath = nested path to attribute with data to store
      - outfpath = path to the output pickle file"""
    obj=self.get_nested(attrpath)
    pickle_manager.writefile(obj,self.render(outfpath))

  def save_csv(self,attrpath,outfpath,index=True,dtype_csv_fpath=None):
    """Save dataframe to a CSV file

    Arguments:

      - attrpath = nested path to attribute with the dataframe to store
      - outfpath = path to the output CSV file
      - index = optional boolean, default True, to include the index as a column in the file
      - dtype_csv_fpath = optional (but highly recommended) path to output CSV file listing data types for the columns"""
    df = self.get_nested(attrpath)
    fpt = self.renderstr(self.get_stored(outfpath))
    df.to_csv(fpt,index=index)
    if dtype_csv_fpath is not None:
      dtype_fpath=self.renderstr(self.get_stored(dtype_csv_fpath))
      df.dtypes.to_csv(dtype_fpath,header=True)
  save_csv._outfile_args = ['outfpath','dtype_csv_fpath']

  def reportvalues(self,outfpath,mapping):
    """Write the selected output results to a yaml file
    
    Arguments:
    
      - outfpath = path to the output yaml file
      - mapping = mapping of output field names to object paths suitable for get_nested
    
    No attributes modified.
    Output file is created/overwritten.
    No return value."""
    # outdict=nested.WithNested() #Doesn't work yet: WithNested apparently can't write itself to yaml, even though it should be able to
    outdict={}
    for key,dpath in mapping.items():
      # outdict.set_nested(key,self.get_nested(dpath)) #If using WithNested as above
      outdict[key]=self.get_nested(dpath)
    yaml_manager.writefile(outdict,self.render(outfpath))
    return


_CommandSequenceRequest_props_schema_yaml="""#CommandSequenceRequest
commands:
  type: array"""

class CommandSequenceRequest(WithCommandsRequest):
  """A request to just run a sequence of commands

  User-defined attributes:
  
    - commands = sequence of commands to execute

      Each command is a pair (cmdname, arguments), where:

        - cmdname = name of the object's method to call, as a string
        - arguments = dictionary of arguments to the method: {argname: value,...}"""
  _self_task=True
  _config_attrs=('commands',)
  _validation_schema=WithCommandsRequest.update_schema(_CommandSequenceRequest_props_schema_yaml)
  _validation_schema.required=['commands']
  def __init__(self,**kwargs):
    #Initialization from base class
    super(CommandSequenceRequest, self).__init__(**kwargs)
    #Initialize command sequence
    self.init_command_sequence('commands')
  def run(self):
    logger.debug("Running Request",request_class=type(self).__name__,request_name=getattr(self,"name",None))
    #Final checks and preparatory steps
    self.pre_run()
    #Run the command sequence
    self.process_command_sequence(attrpath='commands',singlefunc=None,positional=False)


#Register for loading from yaml
yaml_manager.register_classes([CommandSequenceRequest])
